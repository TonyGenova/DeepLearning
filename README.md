## DeepLearning
Notes on Deep Learning/Neural Networks
  
##### Signaling Functions
 - Threshold Function - either 0 or 1 depending on threshold 
   - so, either fires or it doesn't
 - Sigmoid Function - 1/(1+e^x)
   - gives a continuous result between 0 and 1
 - RELU Function  
 - Hyperbolic Tangent Function - (1-e^-2x)/(1+e^-2x)  
   - continuous result between -1 and 1
